{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question&AnsweringNLP_Model_with_fastai.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeroLeon/NLP_Project_with_FastAI/blob/master/Question%26AnsweringNLP_Model_with_fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pfa9d8LKpyV",
        "colab_type": "text"
      },
      "source": [
        "# QA Model with fastai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itgq3yBmQD3y",
        "colab_type": "code",
        "outputId": "39259e2d-e28c-439a-c7c2-1af2e371d181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount = True)\n",
        "base_dir = '/content/gdrive/My Drive/fastai'\n",
        "path = Path(base_dir +'/models_process/')\n",
        "# path.mkdir(parents=True,exist_ok=True) \n",
        "os.chdir(path) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hrzy0q0Qrnv",
        "colab_type": "code",
        "outputId": "bd291083-762b-4bd5-d86d-935cb6451964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd bert_for_SQuAD_en/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/fastai/models_process/bert_for_SQuAD_en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RPIlkUrL_ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i8MkQGEKt_v",
        "colab_type": "text"
      },
      "source": [
        "##Week1. Test an English Model for pre-studying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHQz3RLMSB0P",
        "colab_type": "text"
      },
      "source": [
        "[Starting from this article](https://rsilveira79.github.io/fermenting_gradients/machine_learning/nlp/pytorch/pytorch-transformer-squad/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89d77PEbLviz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "from pytorch_transformers import BertConfig, BertTokenizer, BertForQuestionAnswering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGSXlhwl-faD",
        "colab_type": "text"
      },
      "source": [
        "**Docstring of BertForQuestionAnswering:**   \n",
        "\n",
        "Bert Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear layers on top of\n",
        "the hidden-states output to compute `span start logits` and `span end logits`).     The BERT model was proposed in\n",
        "`BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding`_\n",
        "by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova. It's a bidirectional transformer\n",
        "pre-trained using a combination of masked language modeling objective and next sentence prediction\n",
        "on a large corpus comprising the Toronto Book Corpus and Wikipedia.\n",
        "\n",
        "This model is a PyTorch `torch.nn.Module`_ sub-class. Use it as a regular PyTorch Module and\n",
        "refer to the PyTorch documentation for all matter related to general usage and behavior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvsXKyzL-gsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI31RzfTN7LN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForQuestionAnswering, BertTokenizer)\n",
        "    # 'xlnet': (XLNetConfig, XLNetForQuestionAnswering, XLNetTokenizer)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQqk04j4LveL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuestionAnswering(object):\n",
        "    def __init__(self, config_file, weight_file, tokenizer_file, model_type ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.config_class, self.model_class, self.tokenizer_class = MODEL_CLASSES[model_type]\n",
        "        self.config = self.config_class.from_json_file(config_file)\n",
        "        self.model = self.model_class(self.config)\n",
        "        self.model.load_state_dict(torch.load(weight_file, map_location=self.device))\n",
        "        self.tokenizer = self.tokenizer_class(tokenizer_file)\n",
        "        self.model_type = model_type\n",
        "    \n",
        "    def to_list(self, tensor):\n",
        "        return tensor.detach().cpu().tolist()\n",
        "\n",
        "    def get_reply(self, question, passage):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids, _ , tokens = self.prepare_features(question, passage)\n",
        "            if self.model_type == 'bert':\n",
        "                span_start,span_end= self.model(input_ids)\n",
        "                answer = tokens[torch.argmax(span_start):torch.argmax(span_end)+1]\n",
        "                answer = self.bert_convert_tokens_to_string(answer)\n",
        "            elif self.model_type == 'xlnet':\n",
        "                input_vector = {'input_ids': input_ids,\n",
        "                                'start_positions': None,\n",
        "                                'end_positions': None }\n",
        "                outputs = self.model(**input_vector)\n",
        "                answer = tokens[self.to_list(outputs[1])[0][torch.argmax(outputs[0])]:self.to_list(outputs[3])[0][torch.argmax(outputs[2])]+1]\n",
        "                answer = self.xlnet_convert_tokens_to_string(answer)\n",
        "        return answer\n",
        "    \n",
        "    def bert_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
        "        if '@' in tokens:\n",
        "            out_string = out_string.replace(' ', '')\n",
        "        return out_string\n",
        "\n",
        "    def xlnet_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ''.join(tokens).replace('▁', ' ').strip()\n",
        "        return out_string\n",
        "\n",
        "    def prepare_features(self, question,  passage, max_seq_length = 300, \n",
        "                 zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "        ## Tokenzine Input\n",
        "        tokens_a = self.tokenizer.tokenize(question)\n",
        "        tokens_b = self.tokenizer.tokenize(passage)\n",
        "        ## Truncate\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "        ## Initialize Tokens\n",
        "        tokens = []\n",
        "        if include_CLS_token:\n",
        "            tokens.append(self.tokenizer.cls_token)\n",
        "        ## Add Tokens and separators\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "        if include_SEP_token:\n",
        "            tokens.append(self.tokenizer.sep_token)\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "        ## Convert Tokens to IDs\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        ## Input Mask \n",
        "        input_mask = [1] * len(input_ids)\n",
        "        ## Zero-pad sequence lenght\n",
        "        if zero_pad:\n",
        "            while len(input_ids) < max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                input_mask.append(0)\n",
        "        return torch.tensor(input_ids).unsqueeze(0), input_mask, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_mTFOENaCH",
        "colab_type": "text"
      },
      "source": [
        "###  Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y6PXfqLLvdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = QuestionAnswering(\n",
        "    config_file =   'bert-large-cased-whole-word-masking-finetuned-squad-config.json',\n",
        "    weight_file=    'bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin',\n",
        "    tokenizer_file= 'bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt',\n",
        "    model_type =    'bert'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIB7dW8uLvaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = \" My wife is great. \\\n",
        "My complete name is Roberto Pereira Silveira. \\\n",
        "I am 40 years old. \\\n",
        "My dog is cool. \\\n",
        "My dog breed is jack russel. \\\n",
        "My dog was born in 2014.\\\n",
        "My dog name is Mallu. \\\n",
        "My dog is 5 years old. \\\n",
        "I am an engineer. \\\n",
        "I was born in 1979. \\\n",
        "My e-mail is rsilveira79@gmail.com.\"\n",
        "\n",
        "questions = [\n",
        "    \"What is my complete name?\",\n",
        "    \"What is dog name?\",\n",
        "    \"What is my dog age?\",\n",
        "    \"What is my age?\",\n",
        "    \"What is my dog breed?\",\n",
        "    \"When I was born?\",\n",
        "    \"What is my e-mail?\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBzPgfDPLvW-",
        "colab_type": "code",
        "outputId": "e8bcd86f-e4bf-4594-d3c2-99ae29474f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bert.get_reply(questions[1],facts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mallu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl3ps6jM5NJW",
        "colab_type": "code",
        "outputId": "49309cbb-821e-4d83-ea42-c1091788c803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert.get_reply('What is my dog age?',facts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7GSRAaYKdQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts2 = 'Martin Luther King Jr. was an American Christian minister and activist \\\n",
        "who became the most visible spokesperson and leader in the Civil Rights Movement from 1955 \\\n",
        "until his assassination in 1968.\\\n",
        "Born in Atlanta, Georgia, King is best known for advancing civil rights through nonviolence \\\n",
        "and civil disobedience, inspired by his Christian beliefs and the nonviolent activism of Mahatma Gandhi.\\\n",
        "King led the 1955 Montgomery bus boycott and in 1957 became the first president \\\n",
        "of the Southern Christian Leadership Conference (SCLC). \\\n",
        "With the SCLC, he led an unsuccessful 1962 struggle against segregation in Albany, Georgia, \\\n",
        "and helped organize the nonviolent 1963 protests in Birmingham, Alabama. \\\n",
        "He helped organize the 1963 March on Washington, where he delivered his famous \"I Have a Dream\" speech.'\n",
        "\n",
        "questions2 = [\n",
        "              'Who is Martin Luther King?',\n",
        "              'When did King lead the 1955 Motgomery bus boycott?',\n",
        "              'What beliefs do King have?',\n",
        "              'Is Martin a great people?'\n",
        "]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQcbU_N4R9dP",
        "colab_type": "code",
        "outputId": "8e853334-7061-4d08-f1e4-5d9c0ba8d914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert.get_reply(questions2[0],facts2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an american christian minister and activist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atKXSZdsR9UH",
        "colab_type": "code",
        "outputId": "d0c54602-fe0c-40e4-dd70-dc00cf2041d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert.get_reply(questions2[1],facts2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1955'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icA6uTh-Ulqj",
        "colab_type": "code",
        "outputId": "c049ebe9-c49b-44c0-c59c-4f55367eacf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert.get_reply(questions2[2],facts2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'christian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHHNkmWyVHUG",
        "colab_type": "code",
        "outputId": "0d2f9275-d9f1-4191-b9e6-25ca07c952e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert.get_reply(questions2[3],facts2) # model find no answer so it gives a strange reply"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'martin luther king jr . was an american christian minister and activist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ludM9Erk4-n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ll6q5gtKzMG",
        "colab_type": "text"
      },
      "source": [
        "### Break into pieces and see what they are doing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFkkPMJ7VXOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertTokenizer,BertForQuestionAnswering"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt3qxnFQVXLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained(path_chinese)\n",
        "# bert_model = BertForQuestionAnswering.from_pretrained(path_chinese)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvVFNBmx6Xpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_file =   'bert-large-cased-whole-word-masking-finetuned-squad-config.json'\n",
        "weight_file=    'bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin'\n",
        "tokenizer_file= 'bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt'\n",
        "model_type =    'bert'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
        "config = config_class.from_json_file(config_file)\n",
        "model = model_class(config)\n",
        "model.load_state_dict(torch.load(weight_file, map_location=device))\n",
        "tokenizer = tokenizer_class(tokenizer_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3CrvrB3VXIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens_a = tokenizer.tokenize(questions2[0])\n",
        "tokens_b = tokenizer.tokenize(facts2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-tL9UAZeCUQ",
        "colab_type": "code",
        "outputId": "8e661f0e-19e2-48bb-9350-0293b1e7612b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens_a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['who', 'is', 'ma', '##rt', '##in', 'l', '##uth', '##er', 'king', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jyi82gaeH0q",
        "colab_type": "code",
        "outputId": "fdc9c0a0-4064-4745-8eff-e75113bccfd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokens_b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ma',\n",
              " '##rt',\n",
              " '##in',\n",
              " 'l',\n",
              " '##uth',\n",
              " '##er',\n",
              " 'king',\n",
              " 'j',\n",
              " '##r',\n",
              " '.',\n",
              " 'was',\n",
              " 'an',\n",
              " 'am',\n",
              " '##eric',\n",
              " '##an',\n",
              " 'ch',\n",
              " '##rist',\n",
              " '##ian',\n",
              " 'minister',\n",
              " 'and',\n",
              " 'activist',\n",
              " 'who',\n",
              " 'became',\n",
              " 'the',\n",
              " 'most',\n",
              " 'visible',\n",
              " 'spokesperson',\n",
              " 'and',\n",
              " 'leader',\n",
              " 'in',\n",
              " 'the',\n",
              " 'civil',\n",
              " 'rights',\n",
              " 'movement',\n",
              " 'from',\n",
              " '1955',\n",
              " 'until',\n",
              " 'his',\n",
              " 'assassination',\n",
              " 'in',\n",
              " '1968',\n",
              " '.',\n",
              " 'born',\n",
              " 'in',\n",
              " 'at',\n",
              " '##lant',\n",
              " '##a',\n",
              " ',',\n",
              " 'g',\n",
              " '##eor',\n",
              " '##gia',\n",
              " ',',\n",
              " 'king',\n",
              " 'is',\n",
              " 'best',\n",
              " 'known',\n",
              " 'for',\n",
              " 'advancing',\n",
              " 'civil',\n",
              " 'rights',\n",
              " 'through',\n",
              " 'non',\n",
              " '##vio',\n",
              " '##len',\n",
              " '##ce',\n",
              " 'and',\n",
              " 'civil',\n",
              " 'di',\n",
              " '##so',\n",
              " '##bedience',\n",
              " ',',\n",
              " 'inspired',\n",
              " 'by',\n",
              " 'his',\n",
              " 'ch',\n",
              " '##rist',\n",
              " '##ian',\n",
              " 'beliefs',\n",
              " 'and',\n",
              " 'the',\n",
              " 'non',\n",
              " '##vio',\n",
              " '##lent',\n",
              " 'activism',\n",
              " 'of',\n",
              " 'ma',\n",
              " '##hat',\n",
              " '##ma',\n",
              " 'g',\n",
              " '##and',\n",
              " '##hi',\n",
              " '.',\n",
              " 'king',\n",
              " 'led',\n",
              " 'the',\n",
              " '1955',\n",
              " 'mon',\n",
              " '##t',\n",
              " '##go',\n",
              " '##mer',\n",
              " '##y',\n",
              " 'bus',\n",
              " 'boycott',\n",
              " 'and',\n",
              " 'in',\n",
              " '1957',\n",
              " 'became',\n",
              " 'the',\n",
              " 'first',\n",
              " 'president',\n",
              " 'of',\n",
              " 'the',\n",
              " 'southern',\n",
              " 'ch',\n",
              " '##rist',\n",
              " '##ian',\n",
              " 'leadership',\n",
              " 'conference',\n",
              " '(',\n",
              " 's',\n",
              " '##c',\n",
              " '##l',\n",
              " '##c',\n",
              " ')',\n",
              " '.',\n",
              " 'with',\n",
              " 'the',\n",
              " 's',\n",
              " '##c',\n",
              " '##l',\n",
              " '##c',\n",
              " ',',\n",
              " 'he',\n",
              " 'led',\n",
              " 'an',\n",
              " 'unsuccessful',\n",
              " '1962',\n",
              " 'struggle',\n",
              " 'against',\n",
              " 'segregation',\n",
              " 'in',\n",
              " 'al',\n",
              " '##ban',\n",
              " '##y',\n",
              " ',',\n",
              " 'g',\n",
              " '##eor',\n",
              " '##gia',\n",
              " ',',\n",
              " 'and',\n",
              " 'helped',\n",
              " 'organize',\n",
              " 'the',\n",
              " 'non',\n",
              " '##vio',\n",
              " '##lent',\n",
              " '1963',\n",
              " 'protests',\n",
              " 'in',\n",
              " 'bi',\n",
              " '##rming',\n",
              " '##ham',\n",
              " ',',\n",
              " 'al',\n",
              " '##aba',\n",
              " '##ma',\n",
              " '.',\n",
              " 'he',\n",
              " 'helped',\n",
              " 'organize',\n",
              " 'the',\n",
              " '1963',\n",
              " 'march',\n",
              " 'on',\n",
              " 'washing',\n",
              " '##ton',\n",
              " ',',\n",
              " 'where',\n",
              " 'he',\n",
              " 'delivered',\n",
              " 'his',\n",
              " 'famous',\n",
              " '\"',\n",
              " 'i',\n",
              " 'have',\n",
              " 'a',\n",
              " 'dream',\n",
              " '\"',\n",
              " 'speech',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cskZ7znsTRuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 300\n",
        "zero_pad = False\n",
        "include_CLS_token = True\n",
        "include_SEP_token = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSovOEuwK7UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(tokens_a) > max_seq_length - 2:\n",
        "  tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "  ## Initialize Tokens\n",
        "tokens = []\n",
        "if include_CLS_token:\n",
        "    tokens.append(tokenizer.cls_token)\n",
        "## Add Tokens and separators\n",
        "for token in tokens_a:\n",
        "    tokens.append(token)\n",
        "if include_SEP_token:\n",
        "    tokens.append(tokenizer.sep_token)\n",
        "for token in tokens_b:\n",
        "    tokens.append(token)\n",
        "## Convert Tokens to IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "## Zero-pad sequence length\n",
        "if zero_pad:\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "input_ids=torch.tensor(input_ids).unsqueeze(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTa8SvGl8sAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_convert_tokens_to_string(tokens):\n",
        "    out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
        "    if '@' in tokens:\n",
        "        out_string = out_string.replace(' ', '')\n",
        "    return out_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4yIW2E7fYUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_64hlNg1hYP",
        "colab_type": "code",
        "outputId": "a7b3f98c-c1ad-4090-ce65-9e268f748350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "bert_convert_tokens_to_string(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] who is martin luther king ? [SEP] martin luther king jr . was an american christian minister and activist who became the most visible spokesperson and leader in the civil rights movement from 1955 until his assassination in 1968 . born in atlanta , georgia , king is best known for advancing civil rights through nonviolence and civil disobedience , inspired by his christian beliefs and the nonviolent activism of mahatma gandhi . king led the 1955 montgomery bus boycott and in 1957 became the first president of the southern christian leadership conference ( sclc ) . with the sclc , he led an unsuccessful 1962 struggle against segregation in albany , georgia , and helped organize the nonviolent 1963 protests in birmingham , alabama . he helped organize the 1963 march on washington , where he delivered his famous \" i have a dream \" speech .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnzp7EhIfnRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdFLbeB1gO3",
        "colab_type": "code",
        "outputId": "fabc2860-4a37-45b2-b258-4ee6466fba2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  1150,  1110, 12477,  3740,  1394,   181, 15796,  1200,  2226,\n",
              "           136,   102, 12477,  3740,  1394,   181, 15796,  1200,  2226,   179,\n",
              "          1197,   119,  1108,  1126,  1821, 26237,  1389, 22572, 12937,  1811,\n",
              "          3907,  1105,  7041,  1150,  1245,  1103,  1211,  5085, 18391,  1105,\n",
              "          2301,  1107,  1103,  2987,  2266,  2230,  1121,  3115,  1235,  1117,\n",
              "         10395,  1107,  2477,   119,  1255,  1107,  1120,  9180,  1161,   117,\n",
              "           176, 25690,  9037,   117,  2226,  1110,  1436,  1227,  1111, 11120,\n",
              "          2987,  2266,  1194,  1664, 17417,  7836,  2093,  1105,  2987,  4267,\n",
              "          7301, 18100,   117,  3768,  1118,  1117, 22572, 12937,  1811,  8810,\n",
              "          1105,  1103,  1664, 17417, 13147, 18945,  1104, 12477, 11220,  1918,\n",
              "           176,  5709,  3031,   119,  2226,  1521,  1103,  3115, 19863,  1204,\n",
              "          2758,  4027,  1183,  3592, 21423,  1105,  1107,  3034,  1245,  1103,\n",
              "          1148,  2084,  1104,  1103,  2359, 22572, 12937,  1811,  3645,  3511,\n",
              "           113,   188,  1665,  1233,  1665,   114,   119,  1114,  1103,   188,\n",
              "          1665,  1233,  1665,   117,  1119,  1521,  1126,  7285,  2832,  5637,\n",
              "          1222, 21079,  1107,  2393,  7167,  1183,   117,   176, 25690,  9037,\n",
              "           117,  1105,  2375, 11021,  1103,  1664, 17417, 13147,  2826,  7853,\n",
              "          1107, 16516, 21290,  2522,   117,  2393, 19252,  1918,   119,  1119,\n",
              "          2375, 11021,  1103,  2826,  8943,  1113, 13445,  1633,   117,  1187,\n",
              "          1119,  4653,  1117,  2505,   107,   178,  1138,   170,  4185,   107,\n",
              "          4055,   119]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTUSDoNXjcT5",
        "colab_type": "code",
        "outputId": "b8c35a72-65f6-41bd-a7db-6e63d21a6f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokens_b),len(tokens_a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(190, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYkoPULF3MTJ",
        "colab_type": "code",
        "outputId": "d4935407-a2f5-435d-e871-8e0f5f4854d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAN1zwelWyLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    span_start,span_end= model(input_ids)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ_3iTIe31Ys",
        "colab_type": "code",
        "outputId": "e0dc6e2e-5137-47a5-d828-b732907b98ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "span_start"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.0330, -6.0242, -6.9201, -6.4168, -8.7065, -8.7110, -8.4517, -9.2311,\n",
              "         -8.9629, -7.4666, -5.7319, -5.8057,  2.8824, -4.2409, -4.7454, -2.2637,\n",
              "         -5.0260, -5.0597,  0.6874,  5.4085, -2.0698, -2.0541,  3.7607,  6.1215,\n",
              "          4.2154, -1.8216, -1.7151,  2.1633, -1.2228, -1.9775,  2.8837, -3.0268,\n",
              "          0.6732, -3.2847, -2.6450, -2.5519, -2.8807, -3.8289, -1.9853, -5.1151,\n",
              "         -2.0583, -5.2610, -2.1343, -2.2465, -5.3153, -4.4433, -5.8708, -2.4053,\n",
              "         -6.5772, -3.2967, -2.3991, -5.5036, -2.1608, -3.6182, -0.3259, -5.3628,\n",
              "         -2.7122, -7.2459, -6.9572, -6.7593, -2.6473, -6.1814, -5.3302, -4.3319,\n",
              "         -1.7098, -6.0527, -4.6356, -6.9700, -7.7364, -3.9609, -6.2418, -7.4918,\n",
              "         -7.7684, -5.3424, -7.5105, -8.3465, -8.2392, -7.8884, -6.6476, -7.4981,\n",
              "         -8.0787, -6.8077, -6.9893, -4.1639, -8.1352, -5.6401, -4.7722, -7.7572,\n",
              "         -7.9954, -5.8458, -8.1577, -6.8847, -4.5623, -8.0768, -7.9936, -5.9662,\n",
              "         -7.2882, -3.4128, -7.8781, -6.5881, -5.3878, -7.6630, -6.9539, -7.4278,\n",
              "         -3.2954, -5.8726, -7.3094, -5.0325, -5.9634, -8.2012, -8.1810, -8.4612,\n",
              "         -8.1332, -6.5161, -6.6405, -8.8659, -6.6003, -5.1743, -6.5986, -4.2023,\n",
              "         -5.1679, -5.0053, -8.0755, -5.9206, -3.8177, -5.0529, -7.2195, -6.8884,\n",
              "         -5.9350, -6.3074, -5.4399, -5.0876, -7.5397, -8.0257, -7.7266, -7.6626,\n",
              "         -7.8710, -6.6410, -7.9179, -6.9641, -8.2316, -8.8656, -8.2626, -8.2150,\n",
              "         -5.1245, -7.2579, -7.9583, -7.5178, -6.5424, -7.3798, -8.5059, -7.2432,\n",
              "         -8.5874, -7.5531, -9.1820, -8.6869, -9.0883, -8.0245, -8.8903, -8.5895,\n",
              "         -8.7454, -8.6967, -7.3764, -8.0384, -8.5104, -7.5773, -8.9486, -8.9027,\n",
              "         -7.1420, -7.7132, -8.9548, -6.8830, -9.0281, -8.9577, -9.2832, -7.1740,\n",
              "         -9.0637, -8.5003, -8.5144, -6.0304, -7.5885, -8.0363, -8.1808, -5.9637,\n",
              "         -7.0158, -8.9953, -8.6187, -8.7810, -8.9359, -8.1521, -7.5584, -8.0783,\n",
              "         -7.7009, -6.9178, -6.3984, -6.2302, -9.0607, -8.6915, -8.3474, -8.3001,\n",
              "         -6.8818, -9.0416]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oALNgCIkgYb1",
        "colab_type": "code",
        "outputId": "f1acbb5a-e932-4d9c-d79e-f5be72fe2cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.argmax(span_start),torch.argmax(span_end)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(23), tensor(32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7umGyEQgvsx",
        "colab_type": "code",
        "outputId": "42115bad-6781-4aa8-aa39-c2bfedd0f0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens[torch.argmax(span_start)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QAiBosrhAZS",
        "colab_type": "code",
        "outputId": "38245730-3f24-49bd-988c-d7a7fe8d08dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens[-2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'speech'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljrLPak9oLLd",
        "colab_type": "code",
        "outputId": "650abf06-6ae7-4c29-ada3-d9df4e529074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens[torch.argmax(span_end)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'activist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1166plqVTMAR",
        "colab_type": "code",
        "outputId": "7b1c0469-8548-4c91-8848-1e177c3f7e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "answer = tokens[torch.argmax(span_start):torch.argmax(span_end)+1]\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['an',\n",
              " 'am',\n",
              " '##eric',\n",
              " '##an',\n",
              " 'ch',\n",
              " '##rist',\n",
              " '##ian',\n",
              " 'minister',\n",
              " 'and',\n",
              " 'activist']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG6Ev8eZf6C0",
        "colab_type": "code",
        "outputId": "fe250458-546b-4923-d3e3-9f9548fee1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "answer = bert_convert_tokens_to_string(answer)\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an american christian minister and activist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFJ7E2Nn4-f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lW5AgAr4-Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Ttilg5K3Hw",
        "colab_type": "text"
      },
      "source": [
        "##Week2. Train a Chinese Model for QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFfKIAo9cB_z",
        "colab_type": "text"
      },
      "source": [
        "The dataset used for pretraining\n",
        "\n",
        "[A Span-Extraction Dataset for Chinese Machine Reading Comprehension (CMRC 2018)](https://github.com/ymcui/cmrc2018)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ZsggG7V9wI",
        "colab_type": "text"
      },
      "source": [
        "### Test model on Chinese text data with Chinese RoBERTa model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XzF-iMFbxML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adapt QA class to Chinese Model\n",
        "class QuestionAnswering_Chinese(object):\n",
        "    def __init__(self, model_path,config_file, weight_file, tokenizer_file, model_type ):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.config_class, self.model_class, self.tokenizer_class = MODEL_CLASSES[model_type]\n",
        "        self.config = self.config_class.from_json_file(config_file)\n",
        "        # self.model = self.model_class(self.config)\n",
        "        self.model = BertForQuestionAnswering.from_pretrained(path_chinese)\n",
        "        # self.model.load_state_dict(torch.load(weight_file, map_location=self.device))\n",
        "        self.tokenizer = self.tokenizer_class(tokenizer_file)\n",
        "        self.model_type = model_type\n",
        "    \n",
        "    def to_list(self, tensor):\n",
        "        return tensor.detach().cpu().tolist()\n",
        "\n",
        "    def get_reply(self, question, passage):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids, _ , tokens = self.prepare_features(question, passage)\n",
        "            if self.model_type == 'bert':\n",
        "                span_start,span_end= self.model(input_ids)\n",
        "                if (torch.argmax(span_start) <torch.argmax(span_end)):\n",
        "                  answer = tokens[torch.argmax(span_start):torch.argmax(span_end)+1]\n",
        "                else:\n",
        "                  answer = tokens[torch.argmax(span_end):torch.argmax(span_start)+1]\n",
        "                answer = self.bert_convert_tokens_to_string(answer)\n",
        "            elif self.model_type == 'xlnet':\n",
        "                input_vector = {'input_ids': input_ids,\n",
        "                                'start_positions': None,\n",
        "                                'end_positions': None }\n",
        "                outputs = self.model(**input_vector)\n",
        "                answer = tokens[self.to_list(outputs[1])[0][torch.argmax(outputs[0])]:self.to_list(outputs[3])[0][torch.argmax(outputs[2])]+1]\n",
        "                answer = self.xlnet_convert_tokens_to_string(answer)\n",
        "        return answer\n",
        "    \n",
        "    def bert_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
        "        if '@' in tokens:\n",
        "            out_string = out_string.replace(' ', '')\n",
        "        return out_string\n",
        "\n",
        "    def xlnet_convert_tokens_to_string(self, tokens):\n",
        "        out_string = ''.join(tokens).replace('▁', ' ').strip()\n",
        "        return out_string\n",
        "\n",
        "    def prepare_features(self, question,  passage, max_seq_length = 300, \n",
        "                 zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
        "        ## Tokenzine Input\n",
        "        tokens_a = self.tokenizer.tokenize(question)\n",
        "        tokens_b = self.tokenizer.tokenize(passage)\n",
        "        ## Truncate\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "        ## Initialize Tokens\n",
        "        tokens = []\n",
        "        if include_CLS_token:\n",
        "            tokens.append(self.tokenizer.cls_token)\n",
        "        ## Add Tokens and separators\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "        if include_SEP_token:\n",
        "            tokens.append(self.tokenizer.sep_token)\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "        ## Convert Tokens to IDs\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        ## Input Mask \n",
        "        input_mask = [1] * len(input_ids)\n",
        "        ## Zero-pad sequence lenght\n",
        "        if zero_pad:\n",
        "            while len(input_ids) < max_seq_length:\n",
        "                input_ids.append(0)\n",
        "                input_mask.append(0)\n",
        "        return torch.tensor(input_ids).unsqueeze(0), input_mask, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjaS8LYWbn8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_chinese = Path('/content/gdrive/My Drive/fastai/models_process/Roberta_wwm/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AfkF3MWIuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_chinese = QuestionAnswering_Chinese(model_path=path_chinese,\n",
        "    config_file =   '/content/gdrive/My Drive/fastai/models_process/Roberta_wwm/config.json',\n",
        "    weight_file=    '/content/gdrive/My Drive/fastai/models_process/Roberta_wwm/pytorch_model.bin',\n",
        "    tokenizer_file= '/content/gdrive/My Drive/fastai/models_process/Roberta_wwm/vocab.txt',\n",
        "    model_type =    'bert'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mbSTPpmiHtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_text = '庞氏骗局是对金融领域投资诈骗的称呼，是金字塔骗局（Pyramid scheme）的始祖。\\\n",
        "很多非法的传销集团就是用这一招聚敛钱财的，这种骗术是一个名叫查尔斯·庞兹的投机商人“发明”的。\\\n",
        "庞氏骗局在中国又称“拆东墙补西墙”“空手套白狼”。简言之就是利用新投资人的钱来向老投资者支付利息和短期回报，以制造赚钱的假象进而骗取更多的投资。'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TAokhh3iO44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question1 = '什么是庞氏骗局？'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40B531zgiO22",
        "colab_type": "code",
        "outputId": "b42f56d5-4357-4a0e-b99b-bba399209632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "bert_chinese.get_reply(question1,random_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'氏 骗 局 是 对 金 融 领 域 投 资 诈 骗 的 称 呼 ， 是 金 字 塔 骗 局 （ pyramid scheme ） 的 始 祖 。 很 多 非 法 的 传 销 集 团 就 是 用 这 一 招 聚 敛 钱 财 的 ， 这 种 骗 术 是 一 个 名 叫 查 尔 斯 · 庞 兹 的 投 机 商 人 [UNK] 发 明'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57SMxYAUisG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o8UyXgVwiskV",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(path_chinese)\n",
        "bert_model = BertForQuestionAnswering.from_pretrained(path_chinese)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1NsIOc81iskb",
        "colab": {}
      },
      "source": [
        "config_file =   'bert-large-cased-whole-word-masking-finetuned-squad-config.json'\n",
        "weight_file=    'bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin'\n",
        "tokenizer_file= 'bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt'\n",
        "model_type =    'bert'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
        "config = config_class.from_json_file(config_file)\n",
        "model = model_class(config)\n",
        "model.load_state_dict(torch.load(weight_file, map_location=device))\n",
        "tokenizer = tokenizer_class(tokenizer_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sp4JAwyziskd",
        "colab": {}
      },
      "source": [
        "tokens_a = tokenizer.tokenize(question1)\n",
        "tokens_b = tokenizer.tokenize(random_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72c00332-fc16-45fc-f8e6-1209177fb07e",
        "id": "jTIUgNeKiskg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens_a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['什', '么', '是', '庞', '氏', '骗', '局', '？']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a1337a8f-8f38-47df-d67e-b5a548836a2b",
        "id": "5tf99RS5iskj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokens_b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['庞',\n",
              " '氏',\n",
              " '骗',\n",
              " '局',\n",
              " '是',\n",
              " '对',\n",
              " '金',\n",
              " '融',\n",
              " '领',\n",
              " '域',\n",
              " '投',\n",
              " '资',\n",
              " '诈',\n",
              " '骗',\n",
              " '的',\n",
              " '称',\n",
              " '呼',\n",
              " '，',\n",
              " '是',\n",
              " '金',\n",
              " '字',\n",
              " '塔',\n",
              " '骗',\n",
              " '局',\n",
              " '（',\n",
              " 'p',\n",
              " '##y',\n",
              " '##ram',\n",
              " '##id',\n",
              " 'sc',\n",
              " '##he',\n",
              " '##me',\n",
              " '）',\n",
              " '的',\n",
              " '始',\n",
              " '祖',\n",
              " '。',\n",
              " '很',\n",
              " '多',\n",
              " '非',\n",
              " '法',\n",
              " '的',\n",
              " '传',\n",
              " '销',\n",
              " '集',\n",
              " '团',\n",
              " '就',\n",
              " '是',\n",
              " '用',\n",
              " '这',\n",
              " '一',\n",
              " '招',\n",
              " '聚',\n",
              " '敛',\n",
              " '钱',\n",
              " '财',\n",
              " '的',\n",
              " '，',\n",
              " '这',\n",
              " '种',\n",
              " '骗',\n",
              " '术',\n",
              " '是',\n",
              " '一',\n",
              " '个',\n",
              " '名',\n",
              " '叫',\n",
              " '查',\n",
              " '尔',\n",
              " '斯',\n",
              " '·',\n",
              " '庞',\n",
              " '兹',\n",
              " '的',\n",
              " '投',\n",
              " '机',\n",
              " '商',\n",
              " '人',\n",
              " '[UNK]',\n",
              " '发',\n",
              " '明',\n",
              " '[UNK]',\n",
              " '的',\n",
              " '。',\n",
              " '庞',\n",
              " '氏',\n",
              " '骗',\n",
              " '局',\n",
              " '在',\n",
              " '中',\n",
              " '国',\n",
              " '又',\n",
              " '称',\n",
              " '[UNK]',\n",
              " '拆',\n",
              " '东',\n",
              " '墙',\n",
              " '补',\n",
              " '西',\n",
              " '墙',\n",
              " '[UNK]',\n",
              " '[UNK]',\n",
              " '空',\n",
              " '手',\n",
              " '套',\n",
              " '白',\n",
              " '狼',\n",
              " '[UNK]',\n",
              " '。',\n",
              " '简',\n",
              " '言',\n",
              " '之',\n",
              " '就',\n",
              " '是',\n",
              " '利',\n",
              " '用',\n",
              " '新',\n",
              " '投',\n",
              " '资',\n",
              " '人',\n",
              " '的',\n",
              " '钱',\n",
              " '来',\n",
              " '向',\n",
              " '老',\n",
              " '投',\n",
              " '资',\n",
              " '者',\n",
              " '支',\n",
              " '付',\n",
              " '利',\n",
              " '息',\n",
              " '和',\n",
              " '短',\n",
              " '期',\n",
              " '回',\n",
              " '报',\n",
              " '，',\n",
              " '以',\n",
              " '制',\n",
              " '造',\n",
              " '赚',\n",
              " '钱',\n",
              " '的',\n",
              " '假',\n",
              " '象',\n",
              " '进',\n",
              " '而',\n",
              " '骗',\n",
              " '取',\n",
              " '更',\n",
              " '多',\n",
              " '的',\n",
              " '投',\n",
              " '资',\n",
              " '。']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUP5HfO5iskl",
        "colab": {}
      },
      "source": [
        "max_seq_length = 300\n",
        "zero_pad = False\n",
        "include_CLS_token = True\n",
        "include_SEP_token = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mNJZe65eiskn",
        "colab": {}
      },
      "source": [
        "if len(tokens_a) > max_seq_length - 2:\n",
        "  tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "  ## Initialize Tokens\n",
        "tokens = []\n",
        "if include_CLS_token:\n",
        "    tokens.append(tokenizer.cls_token)\n",
        "## Add Tokens and separators\n",
        "for token in tokens_a:\n",
        "    tokens.append(token)\n",
        "if include_SEP_token:\n",
        "    tokens.append(tokenizer.sep_token)\n",
        "for token in tokens_b:\n",
        "    tokens.append(token)\n",
        "## Convert Tokens to IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "## Zero-pad sequence length\n",
        "if zero_pad:\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "input_ids=torch.tensor(input_ids).unsqueeze(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y7CvpGG-iskp",
        "colab": {}
      },
      "source": [
        "def bert_convert_tokens_to_string(tokens):\n",
        "    out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
        "    if '@' in tokens:\n",
        "        out_string = out_string.replace(' ', '')\n",
        "    return out_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lyT1-2Cgiskq",
        "colab": {}
      },
      "source": [
        "tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "de6ba83e-4746-4788-cb92-6079f724e5b9",
        "id": "MS6BmcsFisks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "bert_convert_tokens_to_string(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] 什 么 是 庞 氏 骗 局 ？ [SEP] 庞 氏 骗 局 是 对 金 融 领 域 投 资 诈 骗 的 称 呼 ， 是 金 字 塔 骗 局 （ pyramid scheme ） 的 始 祖 。 很 多 非 法 的 传 销 集 团 就 是 用 这 一 招 聚 敛 钱 财 的 ， 这 种 骗 术 是 一 个 名 叫 查 尔 斯 · 庞 兹 的 投 机 商 人 [UNK] 发 明 [UNK] 的 。 庞 氏 骗 局 在 中 国 又 称 [UNK] 拆 东 墙 补 西 墙 [UNK] [UNK] 空 手 套 白 狼 [UNK] 。 简 言 之 就 是 利 用 新 投 资 人 的 钱 来 向 老 投 资 者 支 付 利 息 和 短 期 回 报 ， 以 制 造 赚 钱 的 假 象 进 而 骗 取 更 多 的 投 资 。'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ndjoTum3isku",
        "colab": {}
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "71102283-40e6-47bd-9528-b25bf2bc0a03",
        "id": "kgEyk239iskw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   784,   720,  3221,  2425,  3694,  7745,  2229,  8043,   102,\n",
              "          2425,  3694,  7745,  2229,  3221,  2190,  7032,  6084,  7566,  1818,\n",
              "          2832,  6598,  6400,  7745,  4638,  4917,  1461,  8024,  3221,  7032,\n",
              "          2099,  1849,  7745,  2229,  8020,   158,  8179,  9661,  8601, 11515,\n",
              "          9977,  8505,  8021,  4638,  1993,  4862,   511,  2523,  1914,  7478,\n",
              "          3791,  4638,   837,  7218,  7415,  1730,  2218,  3221,  4500,  6821,\n",
              "           671,  2875,  5471,  3137,  7178,  6568,  4638,  8024,  6821,  4905,\n",
              "          7745,  3318,  3221,   671,   702,  1399,  1373,  3389,  2209,  3172,\n",
              "           185,  2425,  1074,  4638,  2832,  3322,  1555,   782,   100,  1355,\n",
              "          3209,   100,  4638,   511,  2425,  3694,  7745,  2229,  1762,   704,\n",
              "          1744,  1348,  4917,   100,  2858,   691,  1870,  6133,  6205,  1870,\n",
              "           100,   100,  4958,  2797,  1947,  4635,  4331,   100,   511,  5042,\n",
              "          6241,   722,  2218,  3221,  1164,  4500,  3173,  2832,  6598,   782,\n",
              "          4638,  7178,  3341,  1403,  5439,  2832,  6598,  5442,  3118,   802,\n",
              "          1164,  2622,  1469,  4764,  3309,  1726,  2845,  8024,   809,  1169,\n",
              "          6863,  6611,  7178,  4638,   969,  6496,  6822,  5445,  7745,  1357,\n",
              "          3291,  1914,  4638,  2832,  6598,   511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9e3a0404-1db4-4c7e-ac8e-63280ac5f299",
        "id": "KeoikNqRisky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokens_b),len(tokens_a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aae8e59b-0cc9-40a7-b208-bc6d61e583aa",
        "id": "HN3yhuW_isk0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "APOBZljZisk2",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    span_start,span_end= model(input_ids)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d47b7d77-5053-4a69-f50b-7296d11ddd9a",
        "id": "HKzXQ9Igisk9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "span_start"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1809, -4.9494, -7.2212, -7.5759, -7.6350, -8.3451, -9.2880, -8.4027,\n",
              "         -8.5443, -7.9771, -4.2551, -5.5678, -8.3149, -6.4926, -2.9097, -4.5758,\n",
              "         -3.4842, -2.6518, -3.9101, -6.2560, -1.4267, -5.6368, -2.7000, -6.7558,\n",
              "         -6.2690, -3.4655, -4.1038, -4.2167, -3.3466, -4.2871, -4.2026, -4.4519,\n",
              "         -7.4884, -5.7710, -3.0653, -4.4859, -5.3675, -4.4587, -4.5967, -5.7832,\n",
              "         -5.4509, -5.0483, -5.2581, -7.3320, -5.2307, -7.9581, -7.5924, -5.7384,\n",
              "         -5.7428, -6.6199, -5.6846, -7.2540, -5.1651, -4.6019, -4.8054, -5.7441,\n",
              "         -4.8727, -5.7000, -4.7641, -5.1740, -4.8043, -7.8425, -5.8914, -4.8307,\n",
              "         -5.5440, -6.0415, -7.1576, -4.7195, -4.8563, -4.7727, -7.0551, -4.8793,\n",
              "         -5.3432, -4.9334, -5.5517, -7.4773, -6.2997, -5.1078, -5.8286, -6.0578,\n",
              "         -5.6377, -5.1083, -4.3592, -7.2845, -2.1229, -3.1430, -4.0567, -6.1290,\n",
              "         -3.9296, -4.8173, -4.8749, -4.6231, -6.4750, -7.7132, -4.1228, -5.0808,\n",
              "         -8.2383, -5.6928, -3.4395, -8.2661, -5.0665, -7.4356, -5.4438, -5.8110,\n",
              "         -8.4190, -6.7402, -7.3364, -5.3319, -6.4678, -7.0825, -6.0561, -5.9183,\n",
              "         -5.4859, -6.1580, -6.8044, -5.0450, -6.6006, -6.6258, -8.6192, -7.5954,\n",
              "         -5.9464, -5.5601, -4.5350, -6.4592, -6.4842, -5.0967, -4.6553, -3.9175,\n",
              "         -6.4058, -7.1133, -7.3758, -6.1104, -5.0669, -8.0762, -6.3626, -4.5178,\n",
              "         -6.8470, -6.0025, -6.8821, -6.3043, -7.7537, -5.4422, -6.1889, -6.5202,\n",
              "         -8.3070, -5.9147, -7.8956, -6.1264, -6.3133, -7.8621, -6.6487, -7.2778,\n",
              "         -6.6225, -8.6142, -7.3211, -7.5855, -6.2452, -6.2999, -8.0146, -5.4251,\n",
              "         -6.5080, -6.7015, -6.9844, -3.7290, -6.9783, -8.3389]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kudK9Zq1isDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g40vfUh8isBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZELQHasir_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NBTrS7Iir93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6OsDHyHir6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Jd1fFCir1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEA3DGRscU73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_facts = '\"尼尔·奥尔登·阿姆斯特朗（Neil Alden Armstrong，1930年8月5日－2012年8月25日），\\\n",
        "美国宇航员、试飞员、海军飞行员以及大学教授。\\\n",
        "在美国国家航空航天局服役时，阿姆斯特朗于1969年7月21日时成为了第一个踏上月球的宇航员，\\\n",
        "也是第一个在地球外星体上留下脚印的人类成员，而其搭档巴兹·奥尔德林也成为了第二位登上月球后安全返回的人，\\\n",
        "两人在月球表面停留了两个半小时。阿姆斯特朗的首次太空任务是双子星座8号，在这次任务中，他和大卫·斯科特执行了历史上第一次轨道对接。\\\n",
        "1969年7月，阿姆斯特朗在执行他的第二次也是最后一次太空任务阿波罗11号时，迈出了“人类的一大步”。 \\\n",
        "2012年8月25日，因心脏搭桥手术后的并发症逝世，享年82岁。其家人在一份声明中称，阿姆斯特朗死于8月初心脏搭桥手术后的并发症。\\\n",
        "美国总统奥巴马27日下令，全国将在首位成功登月的宇航员阿姆斯特朗葬礼举行之日全天降半旗，向这位传奇人物致敬、寄托哀思。\\\n",
        "阿姆斯特朗逝世消息公布之后，美国及世界各地民众也通过各种方式缅怀这位登月先驱。\\\n",
        "美国航天局月球科学研究所则通过网络呼吁大众“对月亮眨眨眼睛”向他致敬\"'\n",
        "\n",
        "chinese_questions = [\n",
        "                     '谁是尼尔·奥尔登·阿姆斯特朗?',\n",
        "                     '阿姆斯特朗的搭档是谁?',\n",
        "                     '是谁下令在27日向阿姆斯特朗致敬?'\n",
        "]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQOaZcZcU36",
        "colab_type": "code",
        "outputId": "be0b0401-4867-4d2a-a706-ecf19f9dfb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "bert_chinese.get_reply(chinese_questions[2],chinese_facts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'， 美 国 宇 航 员 、 试 飞 员 、 海 军 飞 行 员 以 及 大 学 教 授 。 在 美 国 国 家 航 空 航 天 局 服 役 时 ， 阿 姆 斯 特 朗 于 1969 年 7 月 21 日 时 成 为 了 第 一 个 踏 上 月 球 的 宇 航 员 ， 也 是 第 一 个 在 地 球 外 星 体 上 留 下 脚 印 的 人 类 成 员 ， 而 其 搭 档 巴 兹 · 奥 尔 德 林 也 成 为 了 第 二 位 登 上 月 球 后 安 全 返 回 的 人 ， 两 人 在 月 球 表 面 停 留 了 两 个 半 小 时 。 阿 姆 斯 特 朗 的 首 次 太 空 任 务 是 双 子 星 座 8 号 ， 在 这 次 任 务 中 ， 他 和 大 卫 · 斯 科 特 执 行 了 历 史 上 第 一 次 轨 道 对 接 。 1969 年 7 月 ， 阿 姆 斯 特 朗 在 执 行 他 的 第 二 次 也 是 最 后 一 次 太 空 任 务 阿 波 罗 11 号 时 ， 迈 出 了 [UNK] 人 类 的 一 大 步 [UNK] 。 2012 年 8 月 25 日 ， 因 心 脏 搭 桥 手 术 后 的 并 发 症 逝 世 ， 享 年 82 岁 。 其 家 人 在 一 份 声 明 中 称 ， 阿 姆 斯 特 朗 死 于 8 月 初 心 脏 搭 桥 手 术 后 的 并 发 症 。 美 国 总 统 奥 巴 马 27 日 下 令 ， 全 国 将 在 首 位 成 功 登 月 的 宇 航 员 阿 姆 斯 特 朗 葬 礼 举 行 之 日 全 天 降 半 旗 ， 向 这 位 传 奇'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6fCPJF_M42A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chinese_facts = '《战国无双3》是由光荣和ω-force开发的战国无双系列的正统第三续作。\\\n",
        "本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。\\\n",
        "此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。\\\n",
        "2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。本作中共有20张战场地图（不含村雨城），后来发行的猛将传再新增3张战场地图。\\\n",
        "但游戏内战役数量繁多，部分地图会有兼用的状况，战役虚实则是以光荣发行的2本「战国无双3 人物真书」内容为主，以下是相关介绍。'\n",
        "\n",
        "chinese_questions = [\n",
        "                     '《战国无双3》是由哪两个公司合作开发的？',\n",
        "                     '战国史模式主打哪两个模式？'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYxvpbgOazxN",
        "colab_type": "code",
        "outputId": "c803e825-dba7-4a7d-c19c-c80caaa52f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bert_chinese.get_reply(chinese_questions[0],chinese_facts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'主 轴 ， 分 别 是 以 武 田 信 玄 等 人 为 主 的 《 关 东 三 国 志 》 ， 织 田 信 长 等 人 为 主 的 《 战 国 三 杰 》 ， 石 田 三 成 等 人 为 主 的 《 关 原 的 年 轻 武 者 》 ， 丰 富 游 戏 内 的 剧 情 。 此 部 份 专 门 介 绍 角 色 ， 欲 知 武 器 情 报 、 奥 义'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCanUgjN9_Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7eoVa-T9_Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF6Y4oPCK88W",
        "colab_type": "text"
      },
      "source": [
        "##Week3. Fine-tune the Model on downstream Chinese text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RxMp-tVLMZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNcZDuf8Lcxw",
        "colab_type": "text"
      },
      "source": [
        "##Final Week. Interactive APP for QA Demo on Chinese text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u39Uwv37LfBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}